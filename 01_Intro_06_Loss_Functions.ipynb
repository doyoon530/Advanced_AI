{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "\n",
    "    1.   *torch.nn.L1Loss                     - L1 Loss Function\n",
    "    2.   *torch.nn.MSELoss                    - Mean Square Error Loss Function\n",
    "    3.   *torch.nn.CrossEntropyLoss           - Cross entropy loss function\n",
    "    4.   torch.nn.NLLLoss                    - Negative Log Likelihood loss function\n",
    "    5.   torch.nn.PoissonNLLLoss             - Poisson Negative Log Likelihood loss function\n",
    "    6.   torch.nn.nn.KLDivLoss               - Kullback Leiber Divergence loss function\n",
    "    7.   *torch.nn.BCELoss                    - Binary cross entropy loss function\n",
    "    8.   *torch.BCEWithLogitsLoss             - Binary cross entropy loss with logits function\n",
    "    9.   torch.nn.MarginRankingLoss          - Margin ranking loss function\n",
    "    10.  torch.nn.HingeEmbeddingLoss         - Hinge Embedding Loss function\n",
    "    11.  torch.nn.MultiLabelMarginLoss       - Multi Label Margin loss function\n",
    "    12.  torch.nn.SmoothL1Loss               - Smooth L1 Loss function\n",
    "    13.  torch.nn.MultiLabelSoftMarginLoss   - Multi Label Soft Margin Loss function\n",
    "    14.  torch.nn.CosineEmbeddingLoss        - Cosine Embedding loss function\n",
    "    15.  torch.nn.MultiMarginLoss            - Multi Margin loss function\n",
    "    16.  torch.nn.TripletMarginLoss          - Triplet Margin Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# FUNCTIONAL modules - Implementing each module as functions\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy\n",
    "\n",
    "<img src=\"img/cross_entropy.png\" width=\"700\">  \n",
    "\n",
    "Cross Entropy Loss는 보통 Classification용으로 사용  \n",
    "Linear Model (딥러닝 모델)을 통해서 최종값 (Logit 또는 스코어)이 나오고, `Softmax 함수를 통해 이 값들의 범위는 [0,1], 총 합은 1로 설정`.  \n",
    "`최종 Loss는 One-hot Label (정답 라벨)과의 Cross Entropy`\n",
    "\n",
    "<img src=\"img/cross_entropy_2.png\" width=\"700\">  \n",
    "\n",
    "정답 클래스에 해당하는 스코어에 대해서만 로그합을 구하여 최종 Loss 계산\n",
    "\n",
    "$$ \\text{loss}(x, \\text{class}) = -\\log\\left(\\frac{\\exp(x[\\text{class}])}{\\sum_j \\exp(x[j])}\\right) = -x[\\text{class}] + \\log\\left(\\sum_j \\exp(x[j])\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.718281828459045, 0.1353352832366127, 1.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.exp(1),np.exp(-2),np.exp(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7053845126982411"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1)/(np.exp(1)+np.exp(-2)+np.exp(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1851223516044767"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-2)/(np.exp(1)+np.exp(-2)+np.exp(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25949646034241913"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0)/(np.exp(1)+np.exp(-2)+np.exp(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34955747616986843"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*(1*np.log(0.705))+(0*np.log(0.305))+(0*np.log(0.259))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34955747616986843"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*np.log(0.705)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cross-Entropy Loss를 적용하기 위해서는 Softmax 필요하지만, PyTorch에서는 softmax와 cross-entropy를 합쳐서 계산 해주기 때문에 맨 마지막 layer가 softmax일 필요가 없음`\n",
    "\n",
    "```Python\n",
    "torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "Input tensor size는 일반적으로 (minibatch, Class), class의 range는 [0, C-1].  \n",
    "Target의 shape은 (minibatch, ), target[i]의 range는 [0, C-1].\n",
    "\n",
    "<img src=\"img/cross_entropy_loss.png\" width=\"700\">  <br>\n",
    "\n",
    "<img src=\"img/cross_entropy_loss_2.png\" width=\"700\">  \n",
    "\n",
    "`실제 코드 작성 방법`\n",
    "\n",
    "```Python\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "...\n",
    "loss = criterion(input, target)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy Loss\n",
    "\n",
    "`Class 가 2개인 binary case인 경우에는 BCELoss를 사용`\n",
    "\n",
    "```python\n",
    "torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "`BCELoss는 CrossEntropyLoss와 같이 softmax를 포함하지 않으므로,` softmax 또는 다른 activation function을 따로 적용!!  \n",
    "Binary class이기 때문에 input과 target의 shape이 모두 (minibatch, )  \n",
    "각 minibatch 마다 input 값의 range는 [0,1]이고, target 값은 0 또는 1.  \n",
    "\n",
    "\n",
    "```Python\n",
    "import torch.nn as nn\n",
    "criterion = nn.BCELoss()\n",
    "...\n",
    "loss = criterion(nn.Sigmoid(input), target) # 또는 nn.Softmax(input)\n",
    "```\n",
    "\n",
    "$$\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]$$\n",
    "\n",
    "<img src = \"img/BCELoss.png\" width=\"900\"> <br>\n",
    "<img src = \"img/BCELoss_calc.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Implementation\n",
      "Input Data =  tensor([-0.7372, -0.4945, -0.1636, -0.1335,  0.7359], requires_grad=True)\n",
      "Target Data =  tensor([0., 1., 1., 0., 1.])\n",
      "Output Loss =  tensor(0.6320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "\n",
      "\n",
      "Functional implementation\n",
      "Output Loss =  tensor(0.6320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "\n",
      "\n",
      "Manual implementation\n",
      "Output Loss =  tensor(0.6320, grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Module Implementation\")\n",
    "loss = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "output = torch.randn(5, requires_grad=True)\n",
    "sigmoid_output = sigmoid(output) # CrossEntropy와 달리 sigmoid없으면 오류 발생\n",
    "target_data = torch.empty(5).random_(2) # Binary Target\n",
    "\n",
    "output_loss = loss(sigmoid_output, target_data)\n",
    "output_loss.backward(retain_graph=True)    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "\n",
    "print(\"Input Data = \", output)\n",
    "print(\"Target Data = \", target_data)\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Functional implementation\")\n",
    "output_loss = F.binary_cross_entropy(sigmoid_output, target_data)\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Manual implementation\")\n",
    "output_loss = torch.mean( - ( target_data * torch.log(sigmoid_output) + (1 - target_data) * torch.log(1-sigmoid_output) ) )\n",
    "\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss\n",
    "\n",
    "`BCELoss 앞에 Sigmoid layer 를 추가한 (Sigmoid + BCELoss). 따라서 sigmoid 나 softmax 불필요`\n",
    "\n",
    "```python\n",
    "torch.nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)\n",
    "```\n",
    "\n",
    "만약 Sigmoid를 사용한다면, Sigmoide 와 BCELoss를 사용하는 것 보다는 BCEWithLogitsLoss를 사용하는 것이 더 안정적\n",
    "\n",
    "$$\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_n \\left[ t_n \\cdot \\log \\sigma(x_n)\n",
    "+ (1 - t_n) \\cdot \\log (1 - \\sigma(x_n)) \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module implementation\n",
      "Input Data =  tensor([ 0.6399, -1.0481,  0.2680, -1.1035, -0.3882], requires_grad=True)\n",
      "\n",
      "\n",
      "Target Data =  tensor([0., 1., 1., 0., 1.])\n",
      "\n",
      "\n",
      "Output Loss =  tensor(0.6862, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "\n",
      "\n",
      "Functional implementation\n",
      "Output Loss =  tensor(0.6862, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Module implementation\")\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "input_data = torch.randn(5, requires_grad=True)\n",
    "sigmoid_input_data = sigmoid(input_data) \n",
    "\n",
    "target_data = torch.empty(5).random_(2) # Binary Target\n",
    "\n",
    "output_loss = loss(sigmoid_input_data, target_data)\n",
    "output_loss.backward(retain_graph=True)    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "\n",
    "print(\"Input Data = \", input_data)\n",
    "print(\"\\n\")\n",
    "print(\"Target Data = \", target_data)\n",
    "print(\"\\n\")\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Functional implementation\")\n",
    "output_loss = F.binary_cross_entropy_with_logits(sigmoid_input_data, target_data)\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "print(\"Output Loss = \", output_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 loss Function\n",
    "\n",
    "\n",
    "`nn.L1Loss`: Creates a criterion that measures the mean absolute value of the element-wise difference between input x and target y\n",
    "    \n",
    "$$\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = \\left| x_n - y_n \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module implementation\n",
      "Input Data =  tensor([ 0.2909,  0.1518, -0.6119,  0.5733, -2.5542,  0.3013, -0.7613, -0.8967,\n",
      "         0.0834,  1.0762], requires_grad=True)\n",
      "Output Loss =  tensor(1.2719, grad_fn=<L1LossBackward0>)\n",
      "\n",
      "\n",
      "Functional implementation\n",
      "Output Loss =  tensor(1.2719, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Module implementation\")\n",
    "loss = nn.L1Loss()\n",
    "input_data = torch.randn(10, requires_grad=True)\n",
    "target_data = torch.randn(10)\n",
    "output_loss = loss(input_data, target_data)\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "\n",
    "print(\"Input Data = \", input_data)\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Functional implementation\")\n",
    "output_loss = F.l1_loss(input_data, target_data, reduction='elementwise_mean')\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "print(\"Output Loss = \", output_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Square Error\n",
    "\n",
    "Mean Squared Error (MSE) 는 딥러닝에서 가장 많이 사용하는 loss.Output은 예측값, target은 정답값.\n",
    "\n",
    "$\\begin{align}\n",
    "{1 \\over n}\\sum_{i=1}^n(\\text{output}_i - \\text{target}_i)^2\n",
    "\\end{align}$\n",
    "\n",
    "\n",
    "```python\n",
    "torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "여기서 input과 target의 shape은 (minibatch, …)으로 동일. 이미지 간의 mse loss를 구한다면, (minibatch, h, w, channel) 이 됨.\n",
    "\n",
    "<img src=\"img/mse_loss.png\" width=\"900\">\n",
    "\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()\n",
    "...\n",
    "loss = criterion(input, target)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module implementation\n",
      "Input Data =  tensor([ 0.5403,  0.6665,  1.2667, -0.6150, -0.5709,  1.1037, -0.8704,  1.4374,\n",
      "         0.0727, -0.6800], requires_grad=True)\n",
      "Output Loss =  tensor(1.5247, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Functional implementation\n",
      "Output Loss =  tensor(1.5247, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Module implementation\")\n",
    "loss = nn.MSELoss()\n",
    "input_data = torch.randn(10, requires_grad=True)\n",
    "target_data = torch.randn(10)\n",
    "output_loss = loss(input_data, target_data)\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "\n",
    "print(\"Input Data = \", input_data)\n",
    "print(\"Output Loss = \", output_loss)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Functional implementation\")\n",
    "output_loss = F.mse_loss(input_data, target_data, reduction='elementwise_mean')\n",
    "output_loss.backward()    # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "print(\"Output Loss = \", output_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy vs MSE\n",
    "\n",
    "`Cross entorpy is better than MSE for classification, even though MSE can work!!`\n",
    "\n",
    "\n",
    "<img src=\"img/loss_case_1.png\" width=720> <img src=\"img/loss_case_2.png\" width=700>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1) Target is given in onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1-  [CE:]1.38, [MSE:]0.81\n",
      "tensor([[0.0000, 0.0000, 0.9163],\n",
      "        [0.0000, 0.9163, 0.0000],\n",
      "        [2.3026, 0.0000, 0.0000]])\n",
      "tensor([[0.0900, 0.0900, 0.3600],\n",
      "        [0.0900, 0.3600, 0.0900],\n",
      "        [0.8100, 0.0400, 0.4900]])\n",
      "Case 2-  [CE:]0.64, [MSE:]0.34\n",
      "tensor([[0.0000, 0.0000, 0.3567],\n",
      "        [0.0000, 0.3567, 0.0000],\n",
      "        [1.2040, 0.0000, 0.0000]])\n",
      "tensor([[0.0100, 0.0400, 0.0900],\n",
      "        [0.0100, 0.0900, 0.0400],\n",
      "        [0.4900, 0.1600, 0.0900]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Case 1\n",
    "output_1 = torch.tensor([[0.3, 0.3, 0.4],[0.3, 0.4, 0.3],[0.1, 0.2, 0.7]], dtype = torch.float32)\n",
    "label_1 = torch.tensor([[0,0,1],[0,1,0],[1,0,0]], dtype = torch.float32) # or torch.tensor([2,1,0]\n",
    "loss_1_ce = torch.mean( torch.sum(-torch.log(output_1) * label_1, dim = 1 ) )\n",
    "loss_1_mse = torch.mean( torch.sum( (output_1 - label_1)**2, dim=1) )\n",
    "print(f\"Case 1-  [CE:]{loss_1_ce:.2f}, [MSE:]{loss_1_mse:.2f}\")\n",
    "print(-torch.log(output_1)*label_1)\n",
    "print((output_1 - label_1)**2)\n",
    "#Case 2\n",
    "output_2 = torch.tensor([[0.1, 0.2, 0.7],[0.1, 0.7, 0.2],[0.3, 0.4, 0.3]], dtype = torch.float32)\n",
    "label_2 = torch.tensor([[0,0,1],[0,1,0],[1,0,0]], dtype = torch.float32) # or torch.tensor([2,1,0]\n",
    "loss_2_ce = torch.mean( torch.sum(-torch.log(output_2) * label_2, dim = 1 ) )\n",
    "loss_2_mse = torch.mean( torch.sum( (output_2 - label_2)**2, dim=1) )\n",
    "print(f\"Case 2-  [CE:]{loss_2_ce:.2f}, [MSE:]{loss_2_mse:.2f}\")\n",
    "print(-torch.log(output_2)*label_2)\n",
    "print((output_2 - label_2)**2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2) Target is given in labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1-  [CE:]1.38, [MSE:]3.41\n",
      "tensor([[2.4079, 2.4079, 1.8326],\n",
      "        [1.2040, 0.9163, 1.2040],\n",
      "        [0.0000, 0.0000, 0.0000]])\n",
      "tensor([[2.8900, 2.8900, 2.5600],\n",
      "        [0.4900, 0.3600, 0.4900],\n",
      "        [0.0100, 0.0400, 0.4900]])\n",
      "Case 2-  [CE:]0.64, [MSE:]3.47\n",
      "tensor([[4.6052, 3.2189, 0.7133],\n",
      "        [2.3026, 0.3567, 1.6094],\n",
      "        [0.0000, 0.0000, 0.0000]])\n",
      "tensor([[3.6100, 3.2400, 1.6900],\n",
      "        [0.8100, 0.0900, 0.6400],\n",
      "        [0.0900, 0.1600, 0.0900]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Case 1\n",
    "output_1 = torch.tensor([[0.3, 0.3, 0.4],[0.3, 0.4, 0.3],[0.1, 0.2, 0.7]], dtype = torch.float32)\n",
    "label_1 = torch.tensor([2, 1, 0]).reshape(3,1)\n",
    "loss_1_ce = torch.mean( -torch.log(torch.gather(output_1, 1, label_1) ) )\n",
    "loss_1_mse = torch.mean( torch.sum( (output_1 - label_1)**2, dim=1) )\n",
    "print(f\"Case 1-  [CE:]{loss_1_ce:.2f}, [MSE:]{loss_1_mse:.2f}\")\n",
    "print(-torch.log(output_1)*label_1)\n",
    "print((output_1 - label_1)**2)\n",
    "#Case 2\n",
    "output_2 = torch.tensor([[0.1, 0.2, 0.7],[0.1, 0.7, 0.2],[0.3, 0.4, 0.3]], dtype = torch.float32)\n",
    "label_2 = torch.tensor([2, 1, 0]).reshape(3,1)\n",
    "loss_2_ce = torch.mean( -torch.log(torch.gather(output_2, 1, label_2) ) )\n",
    "loss_2_mse = torch.mean( torch.sum( (output_2 - label_2)**2, dim=1) )\n",
    "print(f\"Case 2-  [CE:]{loss_2_ce:.2f}, [MSE:]{loss_2_mse:.2f}\")\n",
    "print(-torch.log(output_2)*label_2)\n",
    "print((output_2 - label_2)**2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MSE can impose much higher loss (penaly) for wrong answers!`  \n",
    "`The lowwer the probability corresponding to the correct answer, the higher the penalty`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9320\\3319023339.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  ce = -np.log(output)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "output = np.linspace(0, 1, 100) #\n",
    "ce = -np.log(output)\n",
    "mse = (output-1)**2 # the squared error between output and correct answer\n",
    "\n",
    "plt.plot(output, ce, 'r-', label='Cross Entropy')\n",
    "plt.plot(output, mse, 'b-', label='MSE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Lab 1.` We have three clasess (`dog, cat, and panda`). For given input data, train the following netwok to yield the output corresponding to `cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_size = 10\n",
    "num_classes = 3\n",
    "\n",
    "x = torch.randn(1, input_size)\n",
    "model = nn.Linear(~~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Lab 2.` We have three clasess (`dog, cat, and panda`). For given input data, train the following netwok to yield the output pointing both `dog and cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_size = 10\n",
    "num_classes = 3\n",
    "\n",
    "x = torch.randn(1, input_size)\n",
    "model = nn.Linear( ~~~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf5d689ac1d312cef1fba9545d41ab0482d31686d08c5b391b55a4a6eb2b95c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
