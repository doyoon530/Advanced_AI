{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Using Linear Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "heights = np.array([150, 154, 159, 162, 163, 168, 170, 172, 175, 178, 179, 182, 185, 188, 190], dtype=np.float32).reshape(-1,1)\n",
    "\n",
    "weights = np.array([45, 48.6, 53.1, 55.8, 56.7, 61.2, 63, 64.8, 67.5, 70.2, 71.1, 73.8, 76.5, 79.2, 81], dtype=np.float32).reshape(-1,1)\n",
    "\n",
    "\n",
    "plt_1 = plt.figure(figsize=(10, 6))\n",
    "plt.scatter(heights, weights)\n",
    "plt.xlabel('Height[cm]')\n",
    "plt.ylabel('Weight[Kg]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = torch.tensor(heights, dtype=torch.float32)\n",
    "weights = torch.tensor(weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "std, m = torch.std_mean(heights)\n",
    "heights = (heights - m ) / std\n",
    "#std, m = torch.std_mean(heights_norm)\n",
    "#print(std, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design a neural network\n",
    "\n",
    "### <span style=\"color:yellow\"> Normalization layer is needed!! </span>\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "\n",
    "`Batch Normalization prevents gradient vanishing or exploding`  \n",
    "\n",
    "`BatchNorm1d` requires length of sequence for 1D inputs\n",
    "\n",
    "`BatchNorm1d` requires only `number of channels` for 2D inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n",
      "torch.Size([20, 3, 100])\n"
     ]
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "input = torch.randn(20, 100)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "\n",
    "#BatchNorm1d requires only number of channels (3) for 2D inputs\n",
    "m = nn.BatchNorm1d(3)\n",
    "input = torch.randn(20, 3, 100)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "class linearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm1d(1)        \n",
    "        self.linear = nn.Linear(1, 1)  # input and output is 1 dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "#model = linearRegression()\n",
    "\n",
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1000], loss: 4245.240234 weight [[0.6631307]] bias [1.4424386] \n",
      "Epoch[2/1000], loss: 4077.403564 weight [[0.8574538]] bias [2.70359] \n",
      "Epoch[3/1000], loss: 3916.202881 weight [[1.0481496]] bias [3.9395182] \n",
      "Epoch[4/1000], loss: 3761.376221 weight [[1.2352858]] bias [5.1507277] \n",
      "Epoch[5/1000], loss: 3612.670898 weight [[1.4189286]] bias [6.3377132] \n",
      "Epoch[6/1000], loss: 3469.845215 weight [[1.5991436]] bias [7.500959] \n",
      "Epoch[7/1000], loss: 3332.666992 weight [[1.7759945]] bias [8.64094] \n",
      "Epoch[8/1000], loss: 3200.912598 weight [[1.9495443]] bias [9.7581215] \n",
      "Epoch[9/1000], loss: 3074.367188 weight [[2.1198545]] bias [10.852959] \n",
      "Epoch[10/1000], loss: 2952.825195 weight [[2.2869854]] bias [11.9258995] \n",
      "Epoch[11/1000], loss: 2836.089111 weight [[2.4509966]] bias [12.977382] \n",
      "Epoch[12/1000], loss: 2723.968750 weight [[2.6119463]] bias [14.0078335] \n",
      "Epoch[13/1000], loss: 2616.281006 weight [[2.7698917]] bias [15.017677] \n",
      "Epoch[14/1000], loss: 2512.850830 weight [[2.9248888]] bias [16.007324] \n",
      "Epoch[15/1000], loss: 2413.510254 weight [[3.0769925]] bias [16.977179] \n",
      "Epoch[16/1000], loss: 2318.097412 weight [[3.226257]] bias [17.927635] \n",
      "Epoch[17/1000], loss: 2226.456543 weight [[3.3727353]] bias [18.859083] \n",
      "Epoch[18/1000], loss: 2138.438965 weight [[3.5164793]] bias [19.771902] \n",
      "Epoch[19/1000], loss: 2053.901611 weight [[3.65754]] bias [20.666464] \n",
      "Epoch[20/1000], loss: 1972.706665 weight [[3.7959678]] bias [21.543135] \n",
      "Epoch[21/1000], loss: 1894.721558 weight [[3.9318116]] bias [22.402271] \n",
      "Epoch[22/1000], loss: 1819.820068 weight [[4.0651197]] bias [23.244226] \n",
      "Epoch[23/1000], loss: 1747.879639 weight [[4.195939]] bias [24.069342] \n",
      "Epoch[24/1000], loss: 1678.783447 weight [[4.3243165]] bias [24.877954] \n",
      "Epoch[25/1000], loss: 1612.419189 weight [[4.450298]] bias [25.670395] \n",
      "Epoch[26/1000], loss: 1548.678467 weight [[4.5739274]] bias [26.446987] \n",
      "Epoch[27/1000], loss: 1487.458130 weight [[4.695249]] bias [27.208048] \n",
      "Epoch[28/1000], loss: 1428.657715 weight [[4.8143063]] bias [27.953888] \n",
      "Epoch[29/1000], loss: 1372.182007 weight [[4.931141]] bias [28.68481] \n",
      "Epoch[30/1000], loss: 1317.939331 weight [[5.045795]] bias [29.401115] \n",
      "Epoch[31/1000], loss: 1265.841064 weight [[5.1583085]] bias [30.103092] \n",
      "Epoch[32/1000], loss: 1215.802246 weight [[5.268722]] bias [30.79103] \n",
      "Epoch[33/1000], loss: 1167.741943 weight [[5.3770742]] bias [31.46521] \n",
      "Epoch[34/1000], loss: 1121.581665 weight [[5.483404]] bias [32.125904] \n",
      "Epoch[35/1000], loss: 1077.246338 weight [[5.587749]] bias [32.773388] \n",
      "Epoch[36/1000], loss: 1034.663452 weight [[5.690146]] bias [33.40792] \n",
      "Epoch[37/1000], loss: 993.764221 weight [[5.790632]] bias [34.029762] \n",
      "Epoch[38/1000], loss: 954.481995 weight [[5.8892417]] bias [34.639168] \n",
      "Epoch[39/1000], loss: 916.752563 weight [[5.986011]] bias [35.236385] \n",
      "Epoch[40/1000], loss: 880.514648 weight [[6.080974]] bias [35.82166] \n",
      "Epoch[41/1000], loss: 845.709412 weight [[6.1741643]] bias [36.395226] \n",
      "Epoch[42/1000], loss: 812.280151 weight [[6.265615]] bias [36.95732] \n",
      "Epoch[43/1000], loss: 780.172424 weight [[6.3553586]] bias [37.508175] \n",
      "Epoch[44/1000], loss: 749.334106 weight [[6.443427]] bias [38.04801] \n",
      "Epoch[45/1000], loss: 719.714722 weight [[6.529852]] bias [38.577053] \n",
      "Epoch[46/1000], loss: 691.266296 weight [[6.614663]] bias [39.095512] \n",
      "Epoch[47/1000], loss: 663.942444 weight [[6.697891]] bias [39.603603] \n",
      "Epoch[48/1000], loss: 637.698853 weight [[6.779566]] bias [40.101532] \n",
      "Epoch[49/1000], loss: 612.492615 weight [[6.859716]] bias [40.5895] \n",
      "Epoch[50/1000], loss: 588.282959 weight [[6.9383698]] bias [41.06771] \n",
      "Epoch[51/1000], loss: 565.030334 weight [[7.0155554]] bias [41.536358] \n",
      "Epoch[52/1000], loss: 542.696838 weight [[7.0913005]] bias [41.995632] \n",
      "Epoch[53/1000], loss: 521.246155 weight [[7.1656313]] bias [42.44572] \n",
      "Epoch[54/1000], loss: 500.643433 weight [[7.238575]] bias [42.886806] \n",
      "Epoch[55/1000], loss: 480.855164 weight [[7.310157]] bias [43.31907] \n",
      "Epoch[56/1000], loss: 461.849274 weight [[7.3804026]] bias [43.742687] \n",
      "Epoch[57/1000], loss: 443.594635 weight [[7.449337]] bias [44.157833] \n",
      "Epoch[58/1000], loss: 426.061615 weight [[7.5169845]] bias [44.56468] \n",
      "Epoch[59/1000], loss: 409.221619 weight [[7.5833693]] bias [44.963387] \n",
      "Epoch[60/1000], loss: 393.047241 weight [[7.6485147]] bias [45.35412] \n",
      "Epoch[61/1000], loss: 377.512268 weight [[7.7124443]] bias [45.737038] \n",
      "Epoch[62/1000], loss: 362.591370 weight [[7.775181]] bias [46.112297] \n",
      "Epoch[63/1000], loss: 348.260345 weight [[7.836746]] bias [46.480053] \n",
      "Epoch[64/1000], loss: 334.495697 weight [[7.8971624]] bias [46.84045] \n",
      "Epoch[65/1000], loss: 321.275299 weight [[7.9564505]] bias [47.19364] \n",
      "Epoch[66/1000], loss: 308.577423 weight [[8.014632]] bias [47.53977] \n",
      "Epoch[67/1000], loss: 296.381470 weight [[8.071728]] bias [47.87897] \n",
      "Epoch[68/1000], loss: 284.667664 weight [[8.127757]] bias [48.21139] \n",
      "Epoch[69/1000], loss: 273.416809 weight [[8.182741]] bias [48.537163] \n",
      "Epoch[70/1000], loss: 262.610748 weight [[8.236699]] bias [48.85642] \n",
      "Epoch[71/1000], loss: 252.231766 weight [[8.289649]] bias [49.16929] \n",
      "Epoch[72/1000], loss: 242.263107 weight [[8.341611]] bias [49.475903] \n",
      "Epoch[73/1000], loss: 232.688400 weight [[8.392603]] bias [49.776386] \n",
      "Epoch[74/1000], loss: 223.492096 weight [[8.442643]] bias [50.070858] \n",
      "Epoch[75/1000], loss: 214.659363 weight [[8.491749]] bias [50.35944] \n",
      "Epoch[76/1000], loss: 206.175797 weight [[8.539938]] bias [50.64225] \n",
      "Epoch[77/1000], loss: 198.027512 weight [[8.587228]] bias [50.919407] \n",
      "Epoch[78/1000], loss: 190.201248 weight [[8.633635]] bias [51.191017] \n",
      "Epoch[79/1000], loss: 182.684418 weight [[8.679175]] bias [51.457195] \n",
      "Epoch[80/1000], loss: 175.464676 weight [[8.723866]] bias [51.718052] \n",
      "Epoch[81/1000], loss: 168.530273 weight [[8.767723]] bias [51.97369] \n",
      "Epoch[82/1000], loss: 161.869934 weight [[8.8107605]] bias [52.224216] \n",
      "Epoch[83/1000], loss: 155.472900 weight [[8.852995]] bias [52.46973] \n",
      "Epoch[84/1000], loss: 149.328674 weight [[8.894441]] bias [52.710335] \n",
      "Epoch[85/1000], loss: 143.427307 weight [[8.935113]] bias [52.94613] \n",
      "Epoch[86/1000], loss: 137.759186 weight [[8.975026]] bias [53.177208] \n",
      "Epoch[87/1000], loss: 132.315033 weight [[9.0141945]] bias [53.403664] \n",
      "Epoch[88/1000], loss: 127.086113 weight [[9.052631]] bias [53.62559] \n",
      "Epoch[89/1000], loss: 122.063843 weight [[9.090351]] bias [53.84308] \n",
      "Epoch[90/1000], loss: 117.240097 weight [[9.127367]] bias [54.056217] \n",
      "Epoch[91/1000], loss: 112.606979 weight [[9.1636915]] bias [54.265095] \n",
      "Epoch[92/1000], loss: 108.156952 weight [[9.199338]] bias [54.46979] \n",
      "Epoch[93/1000], loss: 103.882881 weight [[9.234319]] bias [54.670395] \n",
      "Epoch[94/1000], loss: 99.777702 weight [[9.268647]] bias [54.866985] \n",
      "Epoch[95/1000], loss: 95.834801 weight [[9.302335]] bias [55.059647] \n",
      "Epoch[96/1000], loss: 92.047684 weight [[9.335393]] bias [55.248455] \n",
      "Epoch[97/1000], loss: 88.410202 weight [[9.367834]] bias [55.433487] \n",
      "Epoch[98/1000], loss: 84.916519 weight [[9.39967]] bias [55.61482] \n",
      "Epoch[99/1000], loss: 81.560905 weight [[9.430911]] bias [55.792522] \n",
      "Epoch[100/1000], loss: 78.337921 weight [[9.46157]] bias [55.96667] \n",
      "Epoch[101/1000], loss: 75.242325 weight [[9.491656]] bias [56.137337] \n",
      "Epoch[102/1000], loss: 72.269096 weight [[9.521181]] bias [56.30459] \n",
      "Epoch[103/1000], loss: 69.413383 weight [[9.550155]] bias [56.4685] \n",
      "Epoch[104/1000], loss: 66.670456 weight [[9.578588]] bias [56.629128] \n",
      "Epoch[105/1000], loss: 64.035995 weight [[9.606489]] bias [56.786545] \n",
      "Epoch[106/1000], loss: 61.505623 weight [[9.63387]] bias [56.940815] \n",
      "Epoch[107/1000], loss: 59.075241 weight [[9.66074]] bias [57.092] \n",
      "Epoch[108/1000], loss: 56.740917 weight [[9.687108]] bias [57.240158] \n",
      "Epoch[109/1000], loss: 54.498863 weight [[9.712984]] bias [57.385353] \n",
      "Epoch[110/1000], loss: 52.345421 weight [[9.738378]] bias [57.527645] \n",
      "Epoch[111/1000], loss: 50.277088 weight [[9.763296]] bias [57.66709] \n",
      "Epoch[112/1000], loss: 48.290455 weight [[9.78775]] bias [57.80375] \n",
      "Epoch[113/1000], loss: 46.382339 weight [[9.811748]] bias [57.937675] \n",
      "Epoch[114/1000], loss: 44.549637 weight [[9.835297]] bias [58.068924] \n",
      "Epoch[115/1000], loss: 42.789303 weight [[9.858406]] bias [58.197544] \n",
      "Epoch[116/1000], loss: 41.098633 weight [[9.881084]] bias [58.323593] \n",
      "Epoch[117/1000], loss: 39.474731 weight [[9.903339]] bias [58.44712] \n",
      "Epoch[118/1000], loss: 37.915020 weight [[9.9251795]] bias [58.56818] \n",
      "Epoch[119/1000], loss: 36.416885 weight [[9.946611]] bias [58.686817] \n",
      "Epoch[120/1000], loss: 34.978001 weight [[9.967644]] bias [58.80308] \n",
      "Epoch[121/1000], loss: 33.595955 weight [[9.988283]] bias [58.91702] \n",
      "Epoch[122/1000], loss: 32.268559 weight [[10.008537]] bias [59.02868] \n",
      "Epoch[123/1000], loss: 30.993593 weight [[10.028414]] bias [59.138107] \n",
      "Epoch[124/1000], loss: 29.768986 weight [[10.047918]] bias [59.245346] \n",
      "Epoch[125/1000], loss: 28.592798 weight [[10.0670595]] bias [59.35044] \n",
      "Epoch[126/1000], loss: 27.463074 weight [[10.085843]] bias [59.453434] \n",
      "Epoch[127/1000], loss: 26.377996 weight [[10.104276]] bias [59.554367] \n",
      "Epoch[128/1000], loss: 25.335783 weight [[10.122365]] bias [59.65328] \n",
      "Epoch[129/1000], loss: 24.334789 weight [[10.140117]] bias [59.750214] \n",
      "Epoch[130/1000], loss: 23.373327 weight [[10.1575365]] bias [59.84521] \n",
      "Epoch[131/1000], loss: 22.449858 weight [[10.174631]] bias [59.93831] \n",
      "Epoch[132/1000], loss: 21.562874 weight [[10.191407]] bias [60.02954] \n",
      "Epoch[133/1000], loss: 20.710966 weight [[10.20787]] bias [60.11895] \n",
      "Epoch[134/1000], loss: 19.892725 weight [[10.224025]] bias [60.20657] \n",
      "Epoch[135/1000], loss: 19.106806 weight [[10.239879]] bias [60.29244] \n",
      "Epoch[136/1000], loss: 18.351942 weight [[10.255436]] bias [60.37659] \n",
      "Epoch[137/1000], loss: 17.626886 weight [[10.270703]] bias [60.45906] \n",
      "Epoch[138/1000], loss: 16.930487 weight [[10.285686]] bias [60.53988] \n",
      "Epoch[139/1000], loss: 16.261621 weight [[10.300388]] bias [60.61908] \n",
      "Epoch[140/1000], loss: 15.619174 weight [[10.314816]] bias [60.696697] \n",
      "Epoch[141/1000], loss: 15.002126 weight [[10.328976]] bias [60.772762] \n",
      "Epoch[142/1000], loss: 14.409452 weight [[10.34287]] bias [60.847305] \n",
      "Epoch[143/1000], loss: 13.840201 weight [[10.356505]] bias [60.92036] \n",
      "Epoch[144/1000], loss: 13.293430 weight [[10.369886]] bias [60.991955] \n",
      "Epoch[145/1000], loss: 12.768241 weight [[10.383018]] bias [61.062115] \n",
      "Epoch[146/1000], loss: 12.263840 weight [[10.395904]] bias [61.13087] \n",
      "Epoch[147/1000], loss: 11.779365 weight [[10.408548]] bias [61.198254] \n",
      "Epoch[148/1000], loss: 11.314023 weight [[10.420958]] bias [61.26429] \n",
      "Epoch[149/1000], loss: 10.867055 weight [[10.433135]] bias [61.329002] \n",
      "Epoch[150/1000], loss: 10.437778 weight [[10.445086]] bias [61.39242] \n",
      "Epoch[151/1000], loss: 10.025447 weight [[10.456813]] bias [61.454575] \n",
      "Epoch[152/1000], loss: 9.629396 weight [[10.468321]] bias [61.515484] \n",
      "Epoch[153/1000], loss: 9.248993 weight [[10.479614]] bias [61.575172] \n",
      "Epoch[154/1000], loss: 8.883635 weight [[10.490697]] bias [61.63367] \n",
      "Epoch[155/1000], loss: 8.532688 weight [[10.501573]] bias [61.690998] \n",
      "Epoch[156/1000], loss: 8.195628 weight [[10.512245]] bias [61.747177] \n",
      "Epoch[157/1000], loss: 7.871881 weight [[10.522718]] bias [61.802235] \n",
      "Epoch[158/1000], loss: 7.560918 weight [[10.532996]] bias [61.85619] \n",
      "Epoch[159/1000], loss: 7.262249 weight [[10.543082]] bias [61.909065] \n",
      "Epoch[160/1000], loss: 6.975380 weight [[10.55298]] bias [61.960884] \n",
      "Epoch[161/1000], loss: 6.699840 weight [[10.562694]] bias [62.011665] \n",
      "Epoch[162/1000], loss: 6.435183 weight [[10.572226]] bias [62.06143] \n",
      "Epoch[163/1000], loss: 6.181001 weight [[10.581579]] bias [62.110203] \n",
      "Epoch[164/1000], loss: 5.936845 weight [[10.590758]] bias [62.157997] \n",
      "Epoch[165/1000], loss: 5.702346 weight [[10.599766]] bias [62.204838] \n",
      "Epoch[166/1000], loss: 5.477101 weight [[10.608605]] bias [62.25074] \n",
      "Epoch[167/1000], loss: 5.260757 weight [[10.61728]] bias [62.295727] \n",
      "Epoch[168/1000], loss: 5.052952 weight [[10.6257925]] bias [62.339813] \n",
      "Epoch[169/1000], loss: 4.853360 weight [[10.634147]] bias [62.38302] \n",
      "Epoch[170/1000], loss: 4.661647 weight [[10.642344]] bias [62.425358] \n",
      "Epoch[171/1000], loss: 4.477518 weight [[10.65039]] bias [62.46685] \n",
      "Epoch[172/1000], loss: 4.300667 weight [[10.658284]] bias [62.507515] \n",
      "Epoch[173/1000], loss: 4.130791 weight [[10.666032]] bias [62.547363] \n",
      "Epoch[174/1000], loss: 3.967639 weight [[10.673635]] bias [62.586414] \n",
      "Epoch[175/1000], loss: 3.810929 weight [[10.681095]] bias [62.624687] \n",
      "Epoch[176/1000], loss: 3.660407 weight [[10.6884165]] bias [62.662193] \n",
      "Epoch[177/1000], loss: 3.515831 weight [[10.695601]] bias [62.698948] \n",
      "Epoch[178/1000], loss: 3.376971 weight [[10.702652]] bias [62.73497] \n",
      "Epoch[179/1000], loss: 3.243587 weight [[10.709571]] bias [62.77027] \n",
      "Epoch[180/1000], loss: 3.115475 weight [[10.716361]] bias [62.804867] \n",
      "Epoch[181/1000], loss: 2.992421 weight [[10.723024]] bias [62.838768] \n",
      "Epoch[182/1000], loss: 2.874239 weight [[10.729564]] bias [62.871994] \n",
      "Epoch[183/1000], loss: 2.760715 weight [[10.735981]] bias [62.904552] \n",
      "Epoch[184/1000], loss: 2.651682 weight [[10.742278]] bias [62.936462] \n",
      "Epoch[185/1000], loss: 2.546950 weight [[10.748458]] bias [62.96773] \n",
      "Epoch[186/1000], loss: 2.446362 weight [[10.754522]] bias [62.99838] \n",
      "Epoch[187/1000], loss: 2.349741 weight [[10.760473]] bias [63.02841] \n",
      "Epoch[188/1000], loss: 2.256938 weight [[10.766314]] bias [63.057842] \n",
      "Epoch[189/1000], loss: 2.167805 weight [[10.772044]] bias [63.086685] \n",
      "Epoch[190/1000], loss: 2.082191 weight [[10.777668]] bias [63.114952] \n",
      "Epoch[191/1000], loss: 1.999956 weight [[10.783187]] bias [63.142654] \n",
      "Epoch[192/1000], loss: 1.920968 weight [[10.788603]] bias [63.1698] \n",
      "Epoch[193/1000], loss: 1.845106 weight [[10.793918]] bias [63.196404] \n",
      "Epoch[194/1000], loss: 1.772238 weight [[10.799133]] bias [63.222477] \n",
      "Epoch[195/1000], loss: 1.702247 weight [[10.804252]] bias [63.248028] \n",
      "Epoch[196/1000], loss: 1.635021 weight [[10.809275]] bias [63.273067] \n",
      "Epoch[197/1000], loss: 1.570449 weight [[10.814203]] bias [63.297607] \n",
      "Epoch[198/1000], loss: 1.508428 weight [[10.81904]] bias [63.321655] \n",
      "Epoch[199/1000], loss: 1.448856 weight [[10.823787]] bias [63.345222] \n",
      "Epoch[200/1000], loss: 1.391640 weight [[10.8284445]] bias [63.368317] \n",
      "Epoch[201/1000], loss: 1.336686 weight [[10.833015]] bias [63.39095] \n",
      "Epoch[202/1000], loss: 1.283902 weight [[10.837502]] bias [63.41313] \n",
      "Epoch[203/1000], loss: 1.233200 weight [[10.841904]] bias [63.434868] \n",
      "Epoch[204/1000], loss: 1.184502 weight [[10.846224]] bias [63.45617] \n",
      "Epoch[205/1000], loss: 1.137730 weight [[10.850463]] bias [63.477047] \n",
      "Epoch[206/1000], loss: 1.092800 weight [[10.854623]] bias [63.497505] \n",
      "Epoch[207/1000], loss: 1.049648 weight [[10.8587055]] bias [63.517555] \n",
      "Epoch[208/1000], loss: 1.008198 weight [[10.862712]] bias [63.537205] \n",
      "Epoch[209/1000], loss: 0.968385 weight [[10.866643]] bias [63.55646] \n",
      "Epoch[210/1000], loss: 0.930146 weight [[10.8705015]] bias [63.575333] \n",
      "Epoch[211/1000], loss: 0.893414 weight [[10.874288]] bias [63.593826] \n",
      "Epoch[212/1000], loss: 0.858134 weight [[10.878003]] bias [63.61195] \n",
      "Epoch[213/1000], loss: 0.824247 weight [[10.881649]] bias [63.62971] \n",
      "Epoch[214/1000], loss: 0.791702 weight [[10.885227]] bias [63.647118] \n",
      "Epoch[215/1000], loss: 0.760438 weight [[10.888739]] bias [63.664177] \n",
      "Epoch[216/1000], loss: 0.730409 weight [[10.892184]] bias [63.680893] \n",
      "Epoch[217/1000], loss: 0.701569 weight [[10.895566]] bias [63.697277] \n",
      "Epoch[218/1000], loss: 0.673863 weight [[10.898884]] bias [63.713333] \n",
      "Epoch[219/1000], loss: 0.647252 weight [[10.90214]] bias [63.729065] \n",
      "Epoch[220/1000], loss: 0.621699 weight [[10.905335]] bias [63.744484] \n",
      "Epoch[221/1000], loss: 0.597152 weight [[10.908471]] bias [63.759594] \n",
      "Epoch[222/1000], loss: 0.573572 weight [[10.911549]] bias [63.774403] \n",
      "Epoch[223/1000], loss: 0.550924 weight [[10.914569]] bias [63.788914] \n",
      "Epoch[224/1000], loss: 0.529173 weight [[10.917532]] bias [63.803135] \n",
      "Epoch[225/1000], loss: 0.508281 weight [[10.92044]] bias [63.817074] \n",
      "Epoch[226/1000], loss: 0.488210 weight [[10.923294]] bias [63.830734] \n",
      "Epoch[227/1000], loss: 0.468932 weight [[10.926095]] bias [63.84412] \n",
      "Epoch[228/1000], loss: 0.450416 weight [[10.9288435]] bias [63.85724] \n",
      "Epoch[229/1000], loss: 0.432631 weight [[10.9315405]] bias [63.870094] \n",
      "Epoch[230/1000], loss: 0.415550 weight [[10.934187]] bias [63.882694] \n",
      "Epoch[231/1000], loss: 0.399141 weight [[10.936784]] bias [63.89504] \n",
      "Epoch[232/1000], loss: 0.383384 weight [[10.939333]] bias [63.90714] \n",
      "Epoch[233/1000], loss: 0.368247 weight [[10.941834]] bias [63.918995] \n",
      "Epoch[234/1000], loss: 0.353710 weight [[10.944289]] bias [63.930614] \n",
      "Epoch[235/1000], loss: 0.339746 weight [[10.946698]] bias [63.942] \n",
      "Epoch[236/1000], loss: 0.326334 weight [[10.949062]] bias [63.953163] \n",
      "Epoch[237/1000], loss: 0.313446 weight [[10.951382]] bias [63.9641] \n",
      "Epoch[238/1000], loss: 0.301073 weight [[10.953658]] bias [63.97482] \n",
      "Epoch[239/1000], loss: 0.289186 weight [[10.955892]] bias [63.98532] \n",
      "Epoch[240/1000], loss: 0.277771 weight [[10.958084]] bias [63.995613] \n",
      "Epoch[241/1000], loss: 0.266805 weight [[10.960236]] bias [64.0057] \n",
      "Epoch[242/1000], loss: 0.256274 weight [[10.962347]] bias [64.01559] \n",
      "Epoch[243/1000], loss: 0.246155 weight [[10.964418]] bias [64.025276] \n",
      "Epoch[244/1000], loss: 0.236437 weight [[10.966452]] bias [64.03477] \n",
      "Epoch[245/1000], loss: 0.227107 weight [[10.968447]] bias [64.044075] \n",
      "Epoch[246/1000], loss: 0.218137 weight [[10.970405]] bias [64.05319] \n",
      "Epoch[247/1000], loss: 0.209528 weight [[10.972326]] bias [64.062126] \n",
      "Epoch[248/1000], loss: 0.201259 weight [[10.974212]] bias [64.070885] \n",
      "Epoch[249/1000], loss: 0.193313 weight [[10.976062]] bias [64.07947] \n",
      "Epoch[250/1000], loss: 0.185680 weight [[10.977878]] bias [64.087875] \n",
      "Epoch[251/1000], loss: 0.178353 weight [[10.979659]] bias [64.096115] \n",
      "Epoch[252/1000], loss: 0.171315 weight [[10.981407]] bias [64.104195] \n",
      "Epoch[253/1000], loss: 0.164551 weight [[10.983123]] bias [64.112114] \n",
      "Epoch[254/1000], loss: 0.158053 weight [[10.984807]] bias [64.11987] \n",
      "Epoch[255/1000], loss: 0.151814 weight [[10.98646]] bias [64.12747] \n",
      "Epoch[256/1000], loss: 0.145823 weight [[10.988081]] bias [64.134926] \n",
      "Epoch[257/1000], loss: 0.140065 weight [[10.989673]] bias [64.14223] \n",
      "Epoch[258/1000], loss: 0.134536 weight [[10.991234]] bias [64.14938] \n",
      "Epoch[259/1000], loss: 0.129225 weight [[10.992766]] bias [64.156395] \n",
      "Epoch[260/1000], loss: 0.124125 weight [[10.99427]] bias [64.16327] \n",
      "Epoch[261/1000], loss: 0.119224 weight [[10.995746]] bias [64.170006] \n",
      "Epoch[262/1000], loss: 0.114517 weight [[10.997194]] bias [64.176605] \n",
      "Epoch[263/1000], loss: 0.109997 weight [[10.998615]] bias [64.183075] \n",
      "Epoch[264/1000], loss: 0.105654 weight [[11.00001]] bias [64.189415] \n",
      "Epoch[265/1000], loss: 0.101483 weight [[11.001378]] bias [64.195625] \n",
      "Epoch[266/1000], loss: 0.097478 weight [[11.002721]] bias [64.20171] \n",
      "Epoch[267/1000], loss: 0.093631 weight [[11.004039]] bias [64.20768] \n",
      "Epoch[268/1000], loss: 0.089934 weight [[11.005332]] bias [64.213524] \n",
      "Epoch[269/1000], loss: 0.086386 weight [[11.006601]] bias [64.21925] \n",
      "Epoch[270/1000], loss: 0.082976 weight [[11.007847]] bias [64.22487] \n",
      "Epoch[271/1000], loss: 0.079702 weight [[11.009069]] bias [64.23037] \n",
      "Epoch[272/1000], loss: 0.076557 weight [[11.010269]] bias [64.23576] \n",
      "Epoch[273/1000], loss: 0.073535 weight [[11.011446]] bias [64.24105] \n",
      "Epoch[274/1000], loss: 0.070631 weight [[11.012601]] bias [64.24623] \n",
      "Epoch[275/1000], loss: 0.067842 weight [[11.013735]] bias [64.251305] \n",
      "Epoch[276/1000], loss: 0.065166 weight [[11.014847]] bias [64.25628] \n",
      "Epoch[277/1000], loss: 0.062594 weight [[11.015939]] bias [64.261154] \n",
      "Epoch[278/1000], loss: 0.060123 weight [[11.01701]] bias [64.26593] \n",
      "Epoch[279/1000], loss: 0.057751 weight [[11.018061]] bias [64.270615] \n",
      "Epoch[280/1000], loss: 0.055470 weight [[11.019093]] bias [64.2752] \n",
      "Epoch[281/1000], loss: 0.053282 weight [[11.020105]] bias [64.27969] \n",
      "Epoch[282/1000], loss: 0.051180 weight [[11.021099]] bias [64.2841] \n",
      "Epoch[283/1000], loss: 0.049159 weight [[11.022074]] bias [64.28842] \n",
      "Epoch[284/1000], loss: 0.047219 weight [[11.02303]] bias [64.292656] \n",
      "Epoch[285/1000], loss: 0.045355 weight [[11.023969]] bias [64.29681] \n",
      "Epoch[286/1000], loss: 0.043563 weight [[11.02489]] bias [64.30087] \n",
      "Epoch[287/1000], loss: 0.041843 weight [[11.025794]] bias [64.304855] \n",
      "Epoch[288/1000], loss: 0.040192 weight [[11.026681]] bias [64.30876] \n",
      "Epoch[289/1000], loss: 0.038605 weight [[11.027552]] bias [64.312584] \n",
      "Epoch[290/1000], loss: 0.037082 weight [[11.028406]] bias [64.31633] \n",
      "Epoch[291/1000], loss: 0.035620 weight [[11.029244]] bias [64.32] \n",
      "Epoch[292/1000], loss: 0.034216 weight [[11.030067]] bias [64.3236] \n",
      "Epoch[293/1000], loss: 0.032865 weight [[11.030875]] bias [64.327126] \n",
      "Epoch[294/1000], loss: 0.031569 weight [[11.031668]] bias [64.33058] \n",
      "Epoch[295/1000], loss: 0.030324 weight [[11.032445]] bias [64.33397] \n",
      "Epoch[296/1000], loss: 0.029127 weight [[11.033208]] bias [64.33729] \n",
      "Epoch[297/1000], loss: 0.027979 weight [[11.033957]] bias [64.340546] \n",
      "Epoch[298/1000], loss: 0.026874 weight [[11.034692]] bias [64.343735] \n",
      "Epoch[299/1000], loss: 0.025813 weight [[11.035413]] bias [64.34686] \n",
      "Epoch[300/1000], loss: 0.024794 weight [[11.03612]] bias [64.34992] \n",
      "Epoch[301/1000], loss: 0.023817 weight [[11.036815]] bias [64.35292] \n",
      "Epoch[302/1000], loss: 0.022878 weight [[11.037497]] bias [64.355865] \n",
      "Epoch[303/1000], loss: 0.021974 weight [[11.038165]] bias [64.35875] \n",
      "Epoch[304/1000], loss: 0.021107 weight [[11.038821]] bias [64.36157] \n",
      "Epoch[305/1000], loss: 0.020275 weight [[11.039465]] bias [64.36434] \n",
      "Epoch[306/1000], loss: 0.019475 weight [[11.040097]] bias [64.36706] \n",
      "Epoch[307/1000], loss: 0.018705 weight [[11.040717]] bias [64.36972] \n",
      "Epoch[308/1000], loss: 0.017967 weight [[11.041326]] bias [64.37233] \n",
      "Epoch[309/1000], loss: 0.017257 weight [[11.041923]] bias [64.374886] \n",
      "Epoch[310/1000], loss: 0.016575 weight [[11.042509]] bias [64.37739] \n",
      "Epoch[311/1000], loss: 0.015921 weight [[11.043084]] bias [64.37984] \n",
      "Epoch[312/1000], loss: 0.015294 weight [[11.043649]] bias [64.38224] \n",
      "Epoch[313/1000], loss: 0.014690 weight [[11.044203]] bias [64.3846] \n",
      "Epoch[314/1000], loss: 0.014110 weight [[11.044746]] bias [64.38691] \n",
      "Epoch[315/1000], loss: 0.013553 weight [[11.0452795]] bias [64.38917] \n",
      "Epoch[316/1000], loss: 0.013019 weight [[11.045803]] bias [64.39139] \n",
      "Epoch[317/1000], loss: 0.012505 weight [[11.046317]] bias [64.39356] \n",
      "Epoch[318/1000], loss: 0.012011 weight [[11.046822]] bias [64.39569] \n",
      "Epoch[319/1000], loss: 0.011537 weight [[11.047317]] bias [64.39777] \n",
      "Epoch[320/1000], loss: 0.011082 weight [[11.047802]] bias [64.39982] \n",
      "Epoch[321/1000], loss: 0.010645 weight [[11.048279]] bias [64.401825] \n",
      "Epoch[322/1000], loss: 0.010225 weight [[11.048746]] bias [64.403786] \n",
      "Epoch[323/1000], loss: 0.009822 weight [[11.049205]] bias [64.40571] \n",
      "Epoch[324/1000], loss: 0.009435 weight [[11.049655]] bias [64.40759] \n",
      "Epoch[325/1000], loss: 0.009063 weight [[11.0500965]] bias [64.40944] \n",
      "Epoch[326/1000], loss: 0.008706 weight [[11.05053]] bias [64.41125] \n",
      "Epoch[327/1000], loss: 0.008363 weight [[11.050956]] bias [64.413025] \n",
      "Epoch[328/1000], loss: 0.008033 weight [[11.0513735]] bias [64.414764] \n",
      "Epoch[329/1000], loss: 0.007716 weight [[11.051784]] bias [64.416466] \n",
      "Epoch[330/1000], loss: 0.007412 weight [[11.052186]] bias [64.41814] \n",
      "Epoch[331/1000], loss: 0.007120 weight [[11.052581]] bias [64.41978] \n",
      "Epoch[332/1000], loss: 0.006838 weight [[11.052968]] bias [64.42138] \n",
      "Epoch[333/1000], loss: 0.006569 weight [[11.053349]] bias [64.42295] \n",
      "Epoch[334/1000], loss: 0.006310 weight [[11.053721]] bias [64.42449] \n",
      "Epoch[335/1000], loss: 0.006061 weight [[11.054088]] bias [64.426] \n",
      "Epoch[336/1000], loss: 0.005822 weight [[11.054447]] bias [64.42748] \n",
      "Epoch[337/1000], loss: 0.005592 weight [[11.0548]] bias [64.42893] \n",
      "Epoch[338/1000], loss: 0.005372 weight [[11.055146]] bias [64.43035] \n",
      "Epoch[339/1000], loss: 0.005160 weight [[11.055486]] bias [64.43175] \n",
      "Epoch[340/1000], loss: 0.004956 weight [[11.055819]] bias [64.43311] \n",
      "Epoch[341/1000], loss: 0.004761 weight [[11.056146]] bias [64.43445] \n",
      "Epoch[342/1000], loss: 0.004573 weight [[11.056466]] bias [64.43576] \n",
      "Epoch[343/1000], loss: 0.004393 weight [[11.056781]] bias [64.43704] \n",
      "Epoch[344/1000], loss: 0.004220 weight [[11.05709]] bias [64.4383] \n",
      "Epoch[345/1000], loss: 0.004053 weight [[11.057393]] bias [64.43954] \n",
      "Epoch[346/1000], loss: 0.003893 weight [[11.057691]] bias [64.44075] \n",
      "Epoch[347/1000], loss: 0.003739 weight [[11.057982]] bias [64.44193] \n",
      "Epoch[348/1000], loss: 0.003592 weight [[11.058269]] bias [64.44309] \n",
      "Epoch[349/1000], loss: 0.003451 weight [[11.05855]] bias [64.44423] \n",
      "Epoch[350/1000], loss: 0.003315 weight [[11.0588255]] bias [64.44534] \n",
      "Epoch[351/1000], loss: 0.003184 weight [[11.059096]] bias [64.446434] \n",
      "Epoch[352/1000], loss: 0.003059 weight [[11.059362]] bias [64.4475] \n",
      "Epoch[353/1000], loss: 0.002938 weight [[11.059623]] bias [64.448555] \n",
      "Epoch[354/1000], loss: 0.002822 weight [[11.059878]] bias [64.449585] \n",
      "Epoch[355/1000], loss: 0.002711 weight [[11.060129]] bias [64.45059] \n",
      "Epoch[356/1000], loss: 0.002604 weight [[11.060375]] bias [64.451584] \n",
      "Epoch[357/1000], loss: 0.002501 weight [[11.060617]] bias [64.45255] \n",
      "Epoch[358/1000], loss: 0.002402 weight [[11.060855]] bias [64.4535] \n",
      "Epoch[359/1000], loss: 0.002308 weight [[11.061088]] bias [64.45443] \n",
      "Epoch[360/1000], loss: 0.002217 weight [[11.0613165]] bias [64.45534] \n",
      "Epoch[361/1000], loss: 0.002130 weight [[11.061541]] bias [64.45623] \n",
      "Epoch[362/1000], loss: 0.002046 weight [[11.061761]] bias [64.45711] \n",
      "Epoch[363/1000], loss: 0.001965 weight [[11.061976]] bias [64.45796] \n",
      "Epoch[364/1000], loss: 0.001888 weight [[11.062188]] bias [64.4588] \n",
      "Epoch[365/1000], loss: 0.001814 weight [[11.062396]] bias [64.459625] \n",
      "Epoch[366/1000], loss: 0.001742 weight [[11.0626]] bias [64.460434] \n",
      "Epoch[367/1000], loss: 0.001673 weight [[11.0628]] bias [64.46123] \n",
      "Epoch[368/1000], loss: 0.001607 weight [[11.062997]] bias [64.462006] \n",
      "Epoch[369/1000], loss: 0.001543 weight [[11.0631895]] bias [64.46277] \n",
      "Epoch[370/1000], loss: 0.001482 weight [[11.063378]] bias [64.46352] \n",
      "Epoch[371/1000], loss: 0.001424 weight [[11.063564]] bias [64.46425] \n",
      "Epoch[372/1000], loss: 0.001367 weight [[11.063746]] bias [64.464966] \n",
      "Epoch[373/1000], loss: 0.001313 weight [[11.063926]] bias [64.46567] \n",
      "Epoch[374/1000], loss: 0.001262 weight [[11.064101]] bias [64.466354] \n",
      "Epoch[375/1000], loss: 0.001212 weight [[11.064274]] bias [64.467026] \n",
      "Epoch[376/1000], loss: 0.001164 weight [[11.064443]] bias [64.46768] \n",
      "Epoch[377/1000], loss: 0.001118 weight [[11.064609]] bias [64.46833] \n",
      "Epoch[378/1000], loss: 0.001074 weight [[11.064772]] bias [64.46896] \n",
      "Epoch[379/1000], loss: 0.001032 weight [[11.064931]] bias [64.46958] \n",
      "Epoch[380/1000], loss: 0.000991 weight [[11.065087]] bias [64.47019] \n",
      "Epoch[381/1000], loss: 0.000952 weight [[11.065241]] bias [64.47079] \n",
      "Epoch[382/1000], loss: 0.000915 weight [[11.065392]] bias [64.471375] \n",
      "Epoch[383/1000], loss: 0.000878 weight [[11.065539]] bias [64.47195] \n",
      "Epoch[384/1000], loss: 0.000844 weight [[11.065684]] bias [64.47251] \n",
      "Epoch[385/1000], loss: 0.000810 weight [[11.065827]] bias [64.47306] \n",
      "Epoch[386/1000], loss: 0.000778 weight [[11.065968]] bias [64.4736] \n",
      "Epoch[387/1000], loss: 0.000748 weight [[11.066105]] bias [64.47413] \n",
      "Epoch[388/1000], loss: 0.000718 weight [[11.066239]] bias [64.47465] \n",
      "Epoch[389/1000], loss: 0.000690 weight [[11.066372]] bias [64.47515] \n",
      "Epoch[390/1000], loss: 0.000663 weight [[11.066502]] bias [64.47565] \n",
      "Epoch[391/1000], loss: 0.000637 weight [[11.066629]] bias [64.476135] \n",
      "Epoch[392/1000], loss: 0.000612 weight [[11.066754]] bias [64.476616] \n",
      "Epoch[393/1000], loss: 0.000587 weight [[11.066877]] bias [64.47708] \n",
      "Epoch[394/1000], loss: 0.000564 weight [[11.066998]] bias [64.47754] \n",
      "Epoch[395/1000], loss: 0.000542 weight [[11.067116]] bias [64.47799] \n",
      "Epoch[396/1000], loss: 0.000521 weight [[11.067232]] bias [64.47843] \n",
      "Epoch[397/1000], loss: 0.000500 weight [[11.067346]] bias [64.47887] \n",
      "Epoch[398/1000], loss: 0.000480 weight [[11.067457]] bias [64.47929] \n",
      "Epoch[399/1000], loss: 0.000461 weight [[11.067567]] bias [64.4797] \n",
      "Epoch[400/1000], loss: 0.000443 weight [[11.067675]] bias [64.4801] \n",
      "Epoch[401/1000], loss: 0.000426 weight [[11.0677805]] bias [64.4805] \n",
      "Epoch[402/1000], loss: 0.000409 weight [[11.067884]] bias [64.48089] \n",
      "Epoch[403/1000], loss: 0.000393 weight [[11.0679865]] bias [64.48127] \n",
      "Epoch[404/1000], loss: 0.000378 weight [[11.068087]] bias [64.48164] \n",
      "Epoch[405/1000], loss: 0.000363 weight [[11.068185]] bias [64.48201] \n",
      "Epoch[406/1000], loss: 0.000348 weight [[11.068281]] bias [64.48237] \n",
      "Epoch[407/1000], loss: 0.000335 weight [[11.068376]] bias [64.48272] \n",
      "Epoch[408/1000], loss: 0.000322 weight [[11.068468]] bias [64.48306] \n",
      "Epoch[409/1000], loss: 0.000309 weight [[11.068559]] bias [64.4834] \n",
      "Epoch[410/1000], loss: 0.000297 weight [[11.068647]] bias [64.483734] \n",
      "Epoch[411/1000], loss: 0.000285 weight [[11.068735]] bias [64.48406] \n",
      "Epoch[412/1000], loss: 0.000274 weight [[11.068821]] bias [64.48438] \n",
      "Epoch[413/1000], loss: 0.000263 weight [[11.068905]] bias [64.484695] \n",
      "Epoch[414/1000], loss: 0.000253 weight [[11.068988]] bias [64.485] \n",
      "Epoch[415/1000], loss: 0.000243 weight [[11.069069]] bias [64.4853] \n",
      "Epoch[416/1000], loss: 0.000233 weight [[11.069148]] bias [64.485596] \n",
      "Epoch[417/1000], loss: 0.000224 weight [[11.069226]] bias [64.485886] \n",
      "Epoch[418/1000], loss: 0.000215 weight [[11.069303]] bias [64.48617] \n",
      "Epoch[419/1000], loss: 0.000207 weight [[11.069378]] bias [64.48644] \n",
      "Epoch[420/1000], loss: 0.000198 weight [[11.069451]] bias [64.48672] \n",
      "Epoch[421/1000], loss: 0.000191 weight [[11.069524]] bias [64.486984] \n",
      "Epoch[422/1000], loss: 0.000183 weight [[11.069594]] bias [64.48724] \n",
      "Epoch[423/1000], loss: 0.000176 weight [[11.069664]] bias [64.487495] \n",
      "Epoch[424/1000], loss: 0.000169 weight [[11.069733]] bias [64.48775] \n",
      "Epoch[425/1000], loss: 0.000162 weight [[11.069799]] bias [64.48799] \n",
      "Epoch[426/1000], loss: 0.000156 weight [[11.069865]] bias [64.48823] \n",
      "Epoch[427/1000], loss: 0.000150 weight [[11.06993]] bias [64.488464] \n",
      "Epoch[428/1000], loss: 0.000144 weight [[11.069993]] bias [64.48869] \n",
      "Epoch[429/1000], loss: 0.000138 weight [[11.070055]] bias [64.48892] \n",
      "Epoch[430/1000], loss: 0.000133 weight [[11.070116]] bias [64.48914] \n",
      "Epoch[431/1000], loss: 0.000128 weight [[11.070176]] bias [64.48936] \n",
      "Epoch[432/1000], loss: 0.000123 weight [[11.070235]] bias [64.48957] \n",
      "Epoch[433/1000], loss: 0.000118 weight [[11.070293]] bias [64.48978] \n",
      "Epoch[434/1000], loss: 0.000113 weight [[11.07035]] bias [64.48998] \n",
      "Epoch[435/1000], loss: 0.000109 weight [[11.070405]] bias [64.49018] \n",
      "Epoch[436/1000], loss: 0.000104 weight [[11.070459]] bias [64.49038] \n",
      "Epoch[437/1000], loss: 0.000100 weight [[11.070513]] bias [64.49057] \n",
      "Epoch[438/1000], loss: 0.000096 weight [[11.070565]] bias [64.49076] \n",
      "Epoch[439/1000], loss: 0.000093 weight [[11.070617]] bias [64.490944] \n",
      "Epoch[440/1000], loss: 0.000089 weight [[11.070667]] bias [64.49113] \n",
      "Epoch[441/1000], loss: 0.000085 weight [[11.070717]] bias [64.4913] \n",
      "Epoch[442/1000], loss: 0.000082 weight [[11.0707655]] bias [64.49148] \n",
      "Epoch[443/1000], loss: 0.000079 weight [[11.070813]] bias [64.491646] \n",
      "Epoch[444/1000], loss: 0.000076 weight [[11.07086]] bias [64.49181] \n",
      "Epoch[445/1000], loss: 0.000073 weight [[11.070906]] bias [64.491974] \n",
      "Epoch[446/1000], loss: 0.000070 weight [[11.0709505]] bias [64.492134] \n",
      "Epoch[447/1000], loss: 0.000067 weight [[11.070995]] bias [64.492294] \n",
      "Epoch[448/1000], loss: 0.000065 weight [[11.071039]] bias [64.49245] \n",
      "Epoch[449/1000], loss: 0.000062 weight [[11.071082]] bias [64.4926] \n",
      "Epoch[450/1000], loss: 0.000060 weight [[11.071124]] bias [64.492744] \n",
      "Epoch[451/1000], loss: 0.000057 weight [[11.071165]] bias [64.49289] \n",
      "Epoch[452/1000], loss: 0.000055 weight [[11.071205]] bias [64.493034] \n",
      "Epoch[453/1000], loss: 0.000053 weight [[11.071245]] bias [64.49317] \n",
      "Epoch[454/1000], loss: 0.000051 weight [[11.071284]] bias [64.49331] \n",
      "Epoch[455/1000], loss: 0.000049 weight [[11.071322]] bias [64.49345] \n",
      "Epoch[456/1000], loss: 0.000047 weight [[11.07136]] bias [64.493576] \n",
      "Epoch[457/1000], loss: 0.000045 weight [[11.071397]] bias [64.493706] \n",
      "Epoch[458/1000], loss: 0.000043 weight [[11.071433]] bias [64.493835] \n",
      "Epoch[459/1000], loss: 0.000041 weight [[11.071468]] bias [64.49396] \n",
      "Epoch[460/1000], loss: 0.000040 weight [[11.071503]] bias [64.49408] \n",
      "Epoch[461/1000], loss: 0.000038 weight [[11.071537]] bias [64.4942] \n",
      "Epoch[462/1000], loss: 0.000037 weight [[11.07157]] bias [64.494316] \n",
      "Epoch[463/1000], loss: 0.000035 weight [[11.071603]] bias [64.49443] \n",
      "Epoch[464/1000], loss: 0.000034 weight [[11.071635]] bias [64.494545] \n",
      "Epoch[465/1000], loss: 0.000032 weight [[11.071667]] bias [64.49465] \n",
      "Epoch[466/1000], loss: 0.000031 weight [[11.071698]] bias [64.49476] \n",
      "Epoch[467/1000], loss: 0.000030 weight [[11.071729]] bias [64.494865] \n",
      "Epoch[468/1000], loss: 0.000029 weight [[11.071758]] bias [64.494965] \n",
      "Epoch[469/1000], loss: 0.000028 weight [[11.071788]] bias [64.49506] \n",
      "Epoch[470/1000], loss: 0.000027 weight [[11.071816]] bias [64.49516] \n",
      "Epoch[471/1000], loss: 0.000026 weight [[11.071845]] bias [64.49526] \n",
      "Epoch[472/1000], loss: 0.000025 weight [[11.071873]] bias [64.49535] \n",
      "Epoch[473/1000], loss: 0.000024 weight [[11.071899]] bias [64.495445] \n",
      "Epoch[474/1000], loss: 0.000023 weight [[11.071926]] bias [64.49554] \n",
      "Epoch[475/1000], loss: 0.000022 weight [[11.071952]] bias [64.49563] \n",
      "Epoch[476/1000], loss: 0.000021 weight [[11.071978]] bias [64.49571] \n",
      "Epoch[477/1000], loss: 0.000020 weight [[11.072002]] bias [64.4958] \n",
      "Epoch[478/1000], loss: 0.000019 weight [[11.072027]] bias [64.49588] \n",
      "Epoch[479/1000], loss: 0.000019 weight [[11.072051]] bias [64.495964] \n",
      "Epoch[480/1000], loss: 0.000018 weight [[11.072075]] bias [64.49605] \n",
      "Epoch[481/1000], loss: 0.000017 weight [[11.072098]] bias [64.496124] \n",
      "Epoch[482/1000], loss: 0.000016 weight [[11.072121]] bias [64.4962] \n",
      "Epoch[483/1000], loss: 0.000016 weight [[11.072144]] bias [64.49628] \n",
      "Epoch[484/1000], loss: 0.000015 weight [[11.0721655]] bias [64.49635] \n",
      "Epoch[485/1000], loss: 0.000015 weight [[11.072187]] bias [64.49643] \n",
      "Epoch[486/1000], loss: 0.000014 weight [[11.072208]] bias [64.4965] \n",
      "Epoch[487/1000], loss: 0.000013 weight [[11.072229]] bias [64.49657] \n",
      "Epoch[488/1000], loss: 0.000013 weight [[11.072249]] bias [64.496635] \n",
      "Epoch[489/1000], loss: 0.000012 weight [[11.072269]] bias [64.496704] \n",
      "Epoch[490/1000], loss: 0.000012 weight [[11.072289]] bias [64.49677] \n",
      "Epoch[491/1000], loss: 0.000011 weight [[11.072309]] bias [64.49683] \n",
      "Epoch[492/1000], loss: 0.000011 weight [[11.072328]] bias [64.496895] \n",
      "Epoch[493/1000], loss: 0.000011 weight [[11.072347]] bias [64.496956] \n",
      "Epoch[494/1000], loss: 0.000010 weight [[11.072365]] bias [64.49702] \n",
      "Epoch[495/1000], loss: 0.000010 weight [[11.072383]] bias [64.49708] \n",
      "Epoch[496/1000], loss: 0.000009 weight [[11.0724]] bias [64.49714] \n",
      "Epoch[497/1000], loss: 0.000009 weight [[11.072417]] bias [64.4972] \n",
      "Epoch[498/1000], loss: 0.000009 weight [[11.072434]] bias [64.49725] \n",
      "Epoch[499/1000], loss: 0.000008 weight [[11.072451]] bias [64.49731] \n",
      "Epoch[500/1000], loss: 0.000008 weight [[11.072467]] bias [64.49736] \n",
      "Epoch[501/1000], loss: 0.000008 weight [[11.072483]] bias [64.49741] \n",
      "Epoch[502/1000], loss: 0.000007 weight [[11.072499]] bias [64.49747] \n",
      "Epoch[503/1000], loss: 0.000007 weight [[11.072515]] bias [64.49752] \n",
      "Epoch[504/1000], loss: 0.000007 weight [[11.07253]] bias [64.497574] \n",
      "Epoch[505/1000], loss: 0.000007 weight [[11.072545]] bias [64.49762] \n",
      "Epoch[506/1000], loss: 0.000006 weight [[11.072559]] bias [64.497665] \n",
      "Epoch[507/1000], loss: 0.000006 weight [[11.072574]] bias [64.49771] \n",
      "Epoch[508/1000], loss: 0.000006 weight [[11.072588]] bias [64.49776] \n",
      "Epoch[509/1000], loss: 0.000006 weight [[11.072601]] bias [64.4978] \n",
      "Epoch[510/1000], loss: 0.000005 weight [[11.072615]] bias [64.49785] \n",
      "Epoch[511/1000], loss: 0.000005 weight [[11.072628]] bias [64.497894] \n",
      "Epoch[512/1000], loss: 0.000005 weight [[11.072641]] bias [64.49794] \n",
      "Epoch[513/1000], loss: 0.000005 weight [[11.072654]] bias [64.49798] \n",
      "Epoch[514/1000], loss: 0.000005 weight [[11.072666]] bias [64.49802] \n",
      "Epoch[515/1000], loss: 0.000004 weight [[11.072679]] bias [64.498055] \n",
      "Epoch[516/1000], loss: 0.000004 weight [[11.072691]] bias [64.49809] \n",
      "Epoch[517/1000], loss: 0.000004 weight [[11.072702]] bias [64.49813] \n",
      "Epoch[518/1000], loss: 0.000004 weight [[11.072714]] bias [64.49817] \n",
      "Epoch[519/1000], loss: 0.000004 weight [[11.072725]] bias [64.49821] \n",
      "Epoch[520/1000], loss: 0.000004 weight [[11.072737]] bias [64.498245] \n",
      "Epoch[521/1000], loss: 0.000003 weight [[11.072748]] bias [64.49828] \n",
      "Epoch[522/1000], loss: 0.000003 weight [[11.072759]] bias [64.49832] \n",
      "Epoch[523/1000], loss: 0.000003 weight [[11.072769]] bias [64.49835] \n",
      "Epoch[524/1000], loss: 0.000003 weight [[11.07278]] bias [64.49838] \n",
      "Epoch[525/1000], loss: 0.000003 weight [[11.07279]] bias [64.49841] \n",
      "Epoch[526/1000], loss: 0.000003 weight [[11.072801]] bias [64.49844] \n",
      "Epoch[527/1000], loss: 0.000003 weight [[11.07281]] bias [64.498474] \n",
      "Epoch[528/1000], loss: 0.000003 weight [[11.07282]] bias [64.498505] \n",
      "Epoch[529/1000], loss: 0.000002 weight [[11.072829]] bias [64.498535] \n",
      "Epoch[530/1000], loss: 0.000002 weight [[11.072839]] bias [64.498566] \n",
      "Epoch[531/1000], loss: 0.000002 weight [[11.072848]] bias [64.4986] \n",
      "Epoch[532/1000], loss: 0.000002 weight [[11.072857]] bias [64.49863] \n",
      "Epoch[533/1000], loss: 0.000002 weight [[11.0728655]] bias [64.49866] \n",
      "Epoch[534/1000], loss: 0.000002 weight [[11.072874]] bias [64.49869] \n",
      "Epoch[535/1000], loss: 0.000002 weight [[11.072883]] bias [64.49871] \n",
      "Epoch[536/1000], loss: 0.000002 weight [[11.072891]] bias [64.49873] \n",
      "Epoch[537/1000], loss: 0.000002 weight [[11.0729]] bias [64.49876] \n",
      "Epoch[538/1000], loss: 0.000002 weight [[11.072907]] bias [64.49878] \n",
      "Epoch[539/1000], loss: 0.000002 weight [[11.072915]] bias [64.4988] \n",
      "Epoch[540/1000], loss: 0.000002 weight [[11.072923]] bias [64.498825] \n",
      "Epoch[541/1000], loss: 0.000002 weight [[11.07293]] bias [64.49885] \n",
      "Epoch[542/1000], loss: 0.000001 weight [[11.072938]] bias [64.49887] \n",
      "Epoch[543/1000], loss: 0.000001 weight [[11.072946]] bias [64.49889] \n",
      "Epoch[544/1000], loss: 0.000001 weight [[11.072952]] bias [64.49892] \n",
      "Epoch[545/1000], loss: 0.000001 weight [[11.072959]] bias [64.49894] \n",
      "Epoch[546/1000], loss: 0.000001 weight [[11.072966]] bias [64.49896] \n",
      "Epoch[547/1000], loss: 0.000001 weight [[11.072972]] bias [64.498985] \n",
      "Epoch[548/1000], loss: 0.000001 weight [[11.072979]] bias [64.49901] \n",
      "Epoch[549/1000], loss: 0.000001 weight [[11.072986]] bias [64.49903] \n",
      "Epoch[550/1000], loss: 0.000001 weight [[11.072992]] bias [64.499054] \n",
      "Epoch[551/1000], loss: 0.000001 weight [[11.072999]] bias [64.49907] \n",
      "Epoch[552/1000], loss: 0.000001 weight [[11.073005]] bias [64.499084] \n",
      "Epoch[553/1000], loss: 0.000001 weight [[11.07301]] bias [64.4991] \n",
      "Epoch[554/1000], loss: 0.000001 weight [[11.073016]] bias [64.499115] \n",
      "Epoch[555/1000], loss: 0.000001 weight [[11.073022]] bias [64.49913] \n",
      "Epoch[556/1000], loss: 0.000001 weight [[11.073028]] bias [64.499146] \n",
      "Epoch[557/1000], loss: 0.000001 weight [[11.073033]] bias [64.49916] \n",
      "Epoch[558/1000], loss: 0.000001 weight [[11.073039]] bias [64.499176] \n",
      "Epoch[559/1000], loss: 0.000001 weight [[11.073045]] bias [64.49919] \n",
      "Epoch[560/1000], loss: 0.000001 weight [[11.0730505]] bias [64.49921] \n",
      "Epoch[561/1000], loss: 0.000001 weight [[11.073055]] bias [64.49922] \n",
      "Epoch[562/1000], loss: 0.000001 weight [[11.07306]] bias [64.49924] \n",
      "Epoch[563/1000], loss: 0.000001 weight [[11.073065]] bias [64.49925] \n",
      "Epoch[564/1000], loss: 0.000001 weight [[11.07307]] bias [64.49927] \n",
      "Epoch[565/1000], loss: 0.000001 weight [[11.073074]] bias [64.49928] \n",
      "Epoch[566/1000], loss: 0.000001 weight [[11.073079]] bias [64.4993] \n",
      "Epoch[567/1000], loss: 0.000001 weight [[11.073084]] bias [64.49931] \n",
      "Epoch[568/1000], loss: 0.000001 weight [[11.073089]] bias [64.49933] \n",
      "Epoch[569/1000], loss: 0.000001 weight [[11.073093]] bias [64.499344] \n",
      "Epoch[570/1000], loss: 0.000000 weight [[11.073098]] bias [64.49936] \n",
      "Epoch[571/1000], loss: 0.000000 weight [[11.073102]] bias [64.499374] \n",
      "Epoch[572/1000], loss: 0.000000 weight [[11.073106]] bias [64.49939] \n",
      "Epoch[573/1000], loss: 0.000000 weight [[11.07311]] bias [64.499405] \n",
      "Epoch[574/1000], loss: 0.000000 weight [[11.073113]] bias [64.49942] \n",
      "Epoch[575/1000], loss: 0.000000 weight [[11.073117]] bias [64.499435] \n",
      "Epoch[576/1000], loss: 0.000000 weight [[11.073121]] bias [64.49944] \n",
      "Epoch[577/1000], loss: 0.000000 weight [[11.073125]] bias [64.49945] \n",
      "Epoch[578/1000], loss: 0.000000 weight [[11.073129]] bias [64.49946] \n",
      "Epoch[579/1000], loss: 0.000000 weight [[11.0731325]] bias [64.499466] \n",
      "Epoch[580/1000], loss: 0.000000 weight [[11.073136]] bias [64.49947] \n",
      "Epoch[581/1000], loss: 0.000000 weight [[11.07314]] bias [64.49948] \n",
      "Epoch[582/1000], loss: 0.000000 weight [[11.073144]] bias [64.49949] \n",
      "Epoch[583/1000], loss: 0.000000 weight [[11.073148]] bias [64.4995] \n",
      "Epoch[584/1000], loss: 0.000000 weight [[11.073152]] bias [64.499504] \n",
      "Epoch[585/1000], loss: 0.000000 weight [[11.073154]] bias [64.49951] \n",
      "Epoch[586/1000], loss: 0.000000 weight [[11.073157]] bias [64.49952] \n",
      "Epoch[587/1000], loss: 0.000000 weight [[11.07316]] bias [64.49953] \n",
      "Epoch[588/1000], loss: 0.000000 weight [[11.073163]] bias [64.499535] \n",
      "Epoch[589/1000], loss: 0.000000 weight [[11.073166]] bias [64.49954] \n",
      "Epoch[590/1000], loss: 0.000000 weight [[11.073169]] bias [64.49955] \n",
      "Epoch[591/1000], loss: 0.000000 weight [[11.073172]] bias [64.49956] \n",
      "Epoch[592/1000], loss: 0.000000 weight [[11.073174]] bias [64.499565] \n",
      "Epoch[593/1000], loss: 0.000000 weight [[11.073177]] bias [64.49957] \n",
      "Epoch[594/1000], loss: 0.000000 weight [[11.07318]] bias [64.49958] \n",
      "Epoch[595/1000], loss: 0.000000 weight [[11.073183]] bias [64.49959] \n",
      "Epoch[596/1000], loss: 0.000000 weight [[11.073186]] bias [64.499596] \n",
      "Epoch[597/1000], loss: 0.000000 weight [[11.073189]] bias [64.4996] \n",
      "Epoch[598/1000], loss: 0.000000 weight [[11.073192]] bias [64.49961] \n",
      "Epoch[599/1000], loss: 0.000000 weight [[11.0731945]] bias [64.49962] \n",
      "Epoch[600/1000], loss: 0.000000 weight [[11.073197]] bias [64.499626] \n",
      "Epoch[601/1000], loss: 0.000000 weight [[11.0732]] bias [64.49963] \n",
      "Epoch[602/1000], loss: 0.000000 weight [[11.073202]] bias [64.49964] \n",
      "Epoch[603/1000], loss: 0.000000 weight [[11.073204]] bias [64.49965] \n",
      "Epoch[604/1000], loss: 0.000000 weight [[11.073206]] bias [64.49966] \n",
      "Epoch[605/1000], loss: 0.000000 weight [[11.073208]] bias [64.499664] \n",
      "Epoch[606/1000], loss: 0.000000 weight [[11.07321]] bias [64.49967] \n",
      "Epoch[607/1000], loss: 0.000000 weight [[11.073212]] bias [64.49968] \n",
      "Epoch[608/1000], loss: 0.000000 weight [[11.073214]] bias [64.49969] \n",
      "Epoch[609/1000], loss: 0.000000 weight [[11.0732155]] bias [64.499695] \n",
      "Epoch[610/1000], loss: 0.000000 weight [[11.073217]] bias [64.4997] \n",
      "Epoch[611/1000], loss: 0.000000 weight [[11.073219]] bias [64.49971] \n",
      "Epoch[612/1000], loss: 0.000000 weight [[11.073221]] bias [64.49972] \n",
      "Epoch[613/1000], loss: 0.000000 weight [[11.073223]] bias [64.499725] \n",
      "Epoch[614/1000], loss: 0.000000 weight [[11.073225]] bias [64.49973] \n",
      "Epoch[615/1000], loss: 0.000000 weight [[11.073227]] bias [64.49974] \n",
      "Epoch[616/1000], loss: 0.000000 weight [[11.073229]] bias [64.49975] \n",
      "Epoch[617/1000], loss: 0.000000 weight [[11.073231]] bias [64.499756] \n",
      "Epoch[618/1000], loss: 0.000000 weight [[11.073233]] bias [64.49976] \n",
      "Epoch[619/1000], loss: 0.000000 weight [[11.073235]] bias [64.49977] \n",
      "Epoch[620/1000], loss: 0.000000 weight [[11.073236]] bias [64.49978] \n",
      "Epoch[621/1000], loss: 0.000000 weight [[11.073238]] bias [64.49979] \n",
      "Epoch[622/1000], loss: 0.000000 weight [[11.07324]] bias [64.499794] \n",
      "Epoch[623/1000], loss: 0.000000 weight [[11.073242]] bias [64.4998] \n",
      "Epoch[624/1000], loss: 0.000000 weight [[11.073244]] bias [64.49981] \n",
      "Epoch[625/1000], loss: 0.000000 weight [[11.073246]] bias [64.49982] \n",
      "Epoch[626/1000], loss: 0.000000 weight [[11.073248]] bias [64.49982] \n",
      "Epoch[627/1000], loss: 0.000000 weight [[11.07325]] bias [64.49982] \n",
      "Epoch[628/1000], loss: 0.000000 weight [[11.073252]] bias [64.49982] \n",
      "Epoch[629/1000], loss: 0.000000 weight [[11.073253]] bias [64.49982] \n",
      "Epoch[630/1000], loss: 0.000000 weight [[11.073254]] bias [64.49982] \n",
      "Epoch[631/1000], loss: 0.000000 weight [[11.073255]] bias [64.49982] \n",
      "Epoch[632/1000], loss: 0.000000 weight [[11.073256]] bias [64.49982] \n",
      "Epoch[633/1000], loss: 0.000000 weight [[11.0732565]] bias [64.49982] \n",
      "Epoch[634/1000], loss: 0.000000 weight [[11.073257]] bias [64.49982] \n",
      "Epoch[635/1000], loss: 0.000000 weight [[11.073258]] bias [64.49982] \n",
      "Epoch[636/1000], loss: 0.000000 weight [[11.073259]] bias [64.49982] \n",
      "Epoch[637/1000], loss: 0.000000 weight [[11.07326]] bias [64.49982] \n",
      "Epoch[638/1000], loss: 0.000000 weight [[11.073261]] bias [64.49982] \n",
      "Epoch[639/1000], loss: 0.000000 weight [[11.073262]] bias [64.49982] \n",
      "Epoch[640/1000], loss: 0.000000 weight [[11.073263]] bias [64.49982] \n",
      "Epoch[641/1000], loss: 0.000000 weight [[11.073264]] bias [64.49982] \n",
      "Epoch[642/1000], loss: 0.000000 weight [[11.073265]] bias [64.49982] \n",
      "Epoch[643/1000], loss: 0.000000 weight [[11.073266]] bias [64.49982] \n",
      "Epoch[644/1000], loss: 0.000000 weight [[11.073267]] bias [64.49982] \n",
      "Epoch[645/1000], loss: 0.000000 weight [[11.073268]] bias [64.49982] \n",
      "Epoch[646/1000], loss: 0.000000 weight [[11.073269]] bias [64.49982] \n",
      "Epoch[647/1000], loss: 0.000000 weight [[11.07327]] bias [64.49982] \n",
      "Epoch[648/1000], loss: 0.000000 weight [[11.073271]] bias [64.49982] \n",
      "Epoch[649/1000], loss: 0.000000 weight [[11.073272]] bias [64.49982] \n",
      "Epoch[650/1000], loss: 0.000000 weight [[11.073273]] bias [64.49982] \n",
      "Epoch[651/1000], loss: 0.000000 weight [[11.073274]] bias [64.49982] \n",
      "Epoch[652/1000], loss: 0.000000 weight [[11.073275]] bias [64.49982] \n",
      "Epoch[653/1000], loss: 0.000000 weight [[11.073276]] bias [64.49982] \n",
      "Epoch[654/1000], loss: 0.000000 weight [[11.0732765]] bias [64.49982] \n",
      "Epoch[655/1000], loss: 0.000000 weight [[11.073277]] bias [64.49982] \n",
      "Epoch[656/1000], loss: 0.000000 weight [[11.073278]] bias [64.49982] \n",
      "Epoch[657/1000], loss: 0.000000 weight [[11.073279]] bias [64.49982] \n",
      "Epoch[658/1000], loss: 0.000000 weight [[11.07328]] bias [64.49982] \n",
      "Epoch[659/1000], loss: 0.000000 weight [[11.073281]] bias [64.49982] \n",
      "Epoch[660/1000], loss: 0.000000 weight [[11.073282]] bias [64.49982] \n",
      "Epoch[661/1000], loss: 0.000000 weight [[11.073283]] bias [64.49982] \n",
      "Epoch[662/1000], loss: 0.000000 weight [[11.073284]] bias [64.49982] \n",
      "Epoch[663/1000], loss: 0.000000 weight [[11.073285]] bias [64.49982] \n",
      "Epoch[664/1000], loss: 0.000000 weight [[11.073286]] bias [64.49982] \n",
      "Epoch[665/1000], loss: 0.000000 weight [[11.073287]] bias [64.49982] \n",
      "Epoch[666/1000], loss: 0.000000 weight [[11.073288]] bias [64.49982] \n",
      "Epoch[667/1000], loss: 0.000000 weight [[11.073289]] bias [64.49982] \n",
      "Epoch[668/1000], loss: 0.000000 weight [[11.07329]] bias [64.49982] \n",
      "Epoch[669/1000], loss: 0.000000 weight [[11.073291]] bias [64.49982] \n",
      "Epoch[670/1000], loss: 0.000000 weight [[11.073292]] bias [64.49982] \n",
      "Epoch[671/1000], loss: 0.000000 weight [[11.073293]] bias [64.49982] \n",
      "Epoch[672/1000], loss: 0.000000 weight [[11.073294]] bias [64.49982] \n",
      "Epoch[673/1000], loss: 0.000000 weight [[11.073295]] bias [64.49982] \n",
      "Epoch[674/1000], loss: 0.000000 weight [[11.073296]] bias [64.49982] \n",
      "Epoch[675/1000], loss: 0.000000 weight [[11.073297]] bias [64.49982] \n",
      "Epoch[676/1000], loss: 0.000000 weight [[11.0732975]] bias [64.49982] \n",
      "Epoch[677/1000], loss: 0.000000 weight [[11.073298]] bias [64.49982] \n",
      "Epoch[678/1000], loss: 0.000000 weight [[11.073299]] bias [64.49982] \n",
      "Epoch[679/1000], loss: 0.000000 weight [[11.0733]] bias [64.49982] \n",
      "Epoch[680/1000], loss: 0.000000 weight [[11.073301]] bias [64.49982] \n",
      "Epoch[681/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[682/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[683/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[684/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[685/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[686/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[687/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[688/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[689/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[690/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[691/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[692/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[693/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[694/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[695/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[696/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[697/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[698/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[699/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[700/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[701/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[702/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[703/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[704/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[705/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[706/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[707/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[708/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[709/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[710/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[711/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[712/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[713/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[714/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[715/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[716/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[717/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[718/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[719/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[720/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[721/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[722/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[723/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[724/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[725/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[726/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[727/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[728/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[729/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[730/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[731/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[732/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[733/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[734/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[735/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[736/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[737/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[738/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[739/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[740/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[741/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[742/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[743/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[744/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[745/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[746/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[747/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[748/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[749/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[750/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[751/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[752/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[753/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[754/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[755/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[756/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[757/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[758/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[759/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[760/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[761/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[762/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[763/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[764/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[765/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[766/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[767/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[768/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[769/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[770/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[771/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[772/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[773/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[774/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[775/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[776/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[777/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[778/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[779/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[780/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[781/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[782/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[783/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[784/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[785/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[786/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[787/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[788/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[789/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[790/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[791/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[792/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[793/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[794/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[795/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[796/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[797/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[798/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[799/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[800/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[801/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[802/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[803/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[804/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[805/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[806/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[807/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[808/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[809/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[810/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[811/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[812/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[813/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[814/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[815/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[816/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[817/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[818/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[819/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[820/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[821/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[822/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[823/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[824/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[825/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[826/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[827/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[828/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[829/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[830/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[831/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[832/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[833/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[834/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[835/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[836/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[837/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[838/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[839/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[840/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[841/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[842/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[843/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[844/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[845/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[846/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[847/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[848/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[849/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[850/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[851/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[852/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[853/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[854/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[855/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[856/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[857/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[858/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[859/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[860/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[861/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[862/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[863/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[864/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[865/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[866/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[867/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[868/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[869/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[870/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[871/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[872/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[873/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[874/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[875/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[876/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[877/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[878/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[879/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[880/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[881/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[882/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[883/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[884/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[885/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[886/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[887/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[888/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[889/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[890/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[891/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[892/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[893/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[894/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[895/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[896/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[897/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[898/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[899/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[900/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[901/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[902/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[903/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[904/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[905/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[906/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[907/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[908/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[909/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[910/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[911/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[912/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[913/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[914/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[915/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[916/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[917/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[918/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[919/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[920/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[921/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[922/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[923/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[924/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[925/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[926/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[927/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[928/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[929/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[930/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[931/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[932/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[933/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[934/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[935/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[936/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[937/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[938/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[939/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[940/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[941/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[942/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[943/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[944/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[945/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[946/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[947/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[948/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[949/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[950/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[951/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[952/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[953/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[954/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[955/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[956/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[957/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[958/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[959/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[960/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[961/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[962/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[963/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[964/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[965/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[966/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[967/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[968/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[969/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[970/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[971/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[972/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[973/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[974/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[975/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[976/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[977/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[978/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[979/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[980/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[981/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[982/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[983/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[984/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[985/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[986/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[987/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[988/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[989/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[990/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[991/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[992/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[993/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[994/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[995/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[996/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[997/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[998/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[999/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n",
      "Epoch[1000/1000], loss: 0.000000 weight [[11.073302]] bias [64.49982] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # forward\n",
    "    out = model(heights)\n",
    "    loss = criterion(out, weights)\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch[{epoch+1}/{num_epochs}], loss: {loss.item():.6f}', end=' ')\n",
    "    for name, param in model.named_parameters():\n",
    "        print (name, param.data.numpy(), end=' ')\n",
    "    print()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(heights)\n",
    "predict = predict.data.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(heights.numpy(), weights.numpy(), 'ro', label='Original data')\n",
    "plt.plot(heights.numpy(), predict, label='Fitting Line')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2168.4272]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h = torch.tensor([[190]], dtype=torch.float32)\n",
    "model.eval()\n",
    "w = model(h)\n",
    "print(w)\n",
    "#model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Computation\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\04. Lecture\\2022-2_Adv_AI\\Lecture_Notes\\02_Linear_NN_02_Linear_Regression_Weight_Height.ipynb  14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dropbox/04.%20Lecture/2022-2_Adv_AI/Lecture_Notes/02_Linear_NN_02_Linear_Regression_Weight_Height.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m h_norm \u001b[39m=\u001b[39m (h\u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(heights))\u001b[39m/\u001b[39mtorch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mvar(heights)) \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39;49mnorm\u001b[39m.\u001b[39mweight \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mbias\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dropbox/04.%20Lecture/2022-2_Adv_AI/Lecture_Notes/02_Linear_NN_02_Linear_Regression_Weight_Height.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w \u001b[39m=\u001b[39m h_norm \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dropbox/04.%20Lecture/2022-2_Adv_AI/Lecture_Notes/02_Linear_NN_02_Linear_Regression_Weight_Height.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(w)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "h_norm = (h-torch.mean(heights))/torch.sqrt(torch.var(heights)) * model.norm.weight + model.norm.bias\n",
    "w = h_norm * model.linear.weight.data + model.linear.bias.data\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9970af6c6272f912aea970d3aa30162bd36dbb3ebdad53a40420a930d21aa1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
